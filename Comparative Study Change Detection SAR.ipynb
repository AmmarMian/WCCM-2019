{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Comparative Study of Statistical-based Change Detection Methods for Multidimensional and Multitemporal SAR Images\n",
    "\n",
    "Created by: Ammar Mian, SONDRA, CentraleSupélec\n",
    "Date: 24/06/2019\n",
    "Contact: ammar.mian@centralesupelec.fr\n",
    "\n",
    "This notebook aims at giving reproducible code for the World Congress on Condition monitoring 2019 paper on Change detection. System-requirements:\n",
    "* Python 3\n",
    "* Scipy, numpy\n",
    "* tqdm\n",
    "* matplotlib and plotly\n",
    "\n",
    "The simulation computes change detection maps for each statistics function in the **statistic_list** list. The definition of those functions can be found in the file **change_detection_functions.py**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all needed libraries and functions\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode()\n",
    "\n",
    "# Custom functions\n",
    "from generic_functions import *\n",
    "from multivariate_images_tools import *\n",
    "from data_management import *\n",
    "from change_detection_functions import *\n",
    "from monte_carlo_tools import compute_several_statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable parallel processing (or not)\n",
    "enable_multi = True\n",
    "# These two variables serves to split the original image into sub-images to be treated in parallel\n",
    "# In general the optimal parameters are obtained for \n",
    "# number_of_threads_rows*number_of_threads_columns = number of cores on the machine\n",
    "number_of_threads_rows = 2\n",
    "number_of_threads_columns = 2\n",
    "\n",
    "# Plotting backend is either Matplotlib or Plotly\n",
    "plotting_beckend = 'Matplotlib'\n",
    "\n",
    "# Dataset\n",
    "dataset_choice = 'UAVSAR Scene 1'\n",
    "path_to_data = '../Data/'\n",
    "\n",
    "# List of statistics to compute\n",
    "statistic_list = [covariance_equality_glrt_gaussian_statistic, \n",
    "                 covariance_equality_t1_gaussian_statistic,\n",
    "                  covariance_equality_Wald_gaussian_statistic,\n",
    "                 complex_Hotelling_Lawley_trace_statistic,\n",
    "                  scale_and_shape_equality_robust_statistic,\n",
    "                  Kullback_Leibler_statistic,\n",
    "                  Similarity_measure_Meng_Liu,\n",
    "                  Natural_Geodesic_statistic,\n",
    "                Natural_student_t_distance,\n",
    "                Wasserstein_Gaussian_statistic,\n",
    "                 Wasserstein_robust_statistic]\n",
    "statistic_names = [r'Gaussian GLRT', \n",
    "                   r't1 statistic',\n",
    "                   r'Wald statistic',\n",
    "                   r'HTL statistic',\n",
    "                   r'MT statistic',\n",
    "                  r'Kullback Leibler statistic',\n",
    "                   r'MLL statistic',\n",
    "                   r'Natural Gaussian Geodesic statistic',\n",
    "                    r'Natural_student_t_distance',\n",
    "                   r'Wasserstein Gaussian statistic',\n",
    "                  r'Wasserstein robust statistic']\n",
    "args_list = ['log', 'linear', 'log', None, (0.01, 15, 'log'), None, (0.01,15), None, (3,0.01,15),  None, (0.01,15)]\n",
    "number_of_statistics = len(statistic_list)\n",
    "\n",
    "\n",
    "# Sliding windows mask used\n",
    "windows_mask = np.ones((5,5))\n",
    "m_r, m_c = windows_mask.shape\n",
    "\n",
    "# For ROC curve\n",
    "number_of_points = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and plotting dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = fetch_dataset(dataset_choice, path_to_data)\n",
    "for t in range(dataset.number_dates):\n",
    "  plot_Pauli_SAR(dataset.data[:,:,:,t], figsize=dataset.figsize)\n",
    "  plt.title(r'Image at $t=%d$'%t)\n",
    "\n",
    "if dataset.ground_truth is not None:\n",
    "    plt.figure(figsize=dataset.figsize, dpi=80, facecolor='w')\n",
    "    plt.imshow(dataset.ground_truth, aspect='auto')\n",
    "    plt.title('Ground Truth')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing change detection maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_beginning = time.time()\n",
    "function_to_compute = compute_several_statistics\n",
    "function_args = [statistic_list, args_list]\n",
    "results = sliding_windows_treatment_image_time_series_parallel(dataset.data, windows_mask, function_to_compute, \n",
    "                function_args, multi=enable_multi, number_of_threads_rows=number_of_threads_rows,\n",
    "                number_of_threads_columns=number_of_threads_columns, progressbar=True)\n",
    "print('Done.')\n",
    "print(\"Elpased time: %d s\" %(time.time()-t_beginning))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing statistics results raw Matplotlib\n",
    "if plotting_beckend == 'Matplotlib':\n",
    "    for i_s, statistic in enumerate(statistic_names):\n",
    "        image_temp = np.nan*np.ones((dataset.number_rows, dataset.number_columns))\n",
    "        image_temp[int(m_r/2):-int(m_r/2), int(m_c/2):-int(m_c/2)] = (results[:,:,i_s] - results[:,:,i_s].min())\n",
    "        plt.figure(figsize=dataset.figsize, dpi=80, facecolor='w')\n",
    "        plt.imshow(image_temp, aspect='auto')\n",
    "        plt.title(statistic)\n",
    "        plt.axis('off')\n",
    "        plt.colorbar()\n",
    "        plt.savefig('./Results/'+dataset_choice+'/%s_%dx%d.pdf'%(statistic, m_r, m_c) )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing statistics results raw Plotly\n",
    "if plotting_beckend == 'Plotly':\n",
    "    for i_s, statistic in enumerate(statistic_names):\n",
    "        image_temp = np.nan*np.ones((dataset.number_rows, dataset.number_columns))\n",
    "        image_temp[int(m_r/2):-int(m_r/2), int(m_c/2):-int(m_c/2)] = np.flip(results[:,:,i_s] - results[:,:,i_s].min(), axis=0)\n",
    "        trace = go.Heatmap(z=image_temp, colorscale='Jet')\n",
    "        fig = go.Figure(data=[trace])\n",
    "        iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing ROC curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_beginning = time.time()\n",
    "ground_truth = dataset.ground_truth[int(m_r/2):-int(m_r/2), int(m_c/2):-int(m_c/2)]\n",
    "pfa_array = np.zeros((number_of_points, len(function_args[0])))\n",
    "pd_array = np.zeros((number_of_points, len(function_args[0])))\n",
    "for i_s, statistic in enumerate(tqdm(statistic_names)):\n",
    "\n",
    "    # Sorting values of statistic\n",
    "    λ_vec = np.sort(vec(results[:,:,i_s]), axis=0)\n",
    "    λ_vec = λ_vec[np.logical_not(np.isinf(λ_vec))]\n",
    "\n",
    "    # Selectionning number_of_points values from beginning to end\n",
    "    indices_λ = np.floor(np.logspace(0, np.log10(len(λ_vec)-1), num=number_of_points)) # logspace\n",
    "    # indices_λ = np.floor(np.logspace(0, len(λ_vec)-1, num=number_of_points)) # logspace\n",
    "    λ_vec = np.flip(λ_vec, axis=0)\n",
    "    λ_vec = λ_vec[indices_λ.astype(int)]\n",
    "\n",
    "    # Thresholding and summing for each value\n",
    "    for i_λ, λ in enumerate(λ_vec):\n",
    "        good_detection = (results[:,:,i_s] >= λ) * ground_truth\n",
    "        false_alarms = (results[:,:,i_s] >= λ) * np.logical_not(ground_truth)\n",
    "        pd_array[i_λ, i_s] = good_detection.sum() / (ground_truth==1).sum()\n",
    "        pfa_array[i_λ, i_s] = false_alarms.sum() / (ground_truth==0).sum()\n",
    "print('Done.')\n",
    "print(\"Elpased time: %d s\" %(time.time()-t_beginning))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing statistics results ROC with matplotlib\n",
    "import matplotlib2tikz\n",
    "markers = ['o', 's', 'h', '*', 'd', 'p', '+', '^', '>', '<']\n",
    "plt.figure(figsize=(6, 4), dpi=120, facecolor='w')\n",
    "for i_s, statistic in enumerate(statistic_names):\n",
    "    plt.semilogx(pfa_array[:,i_s], pd_array[:,i_s], linestyle='--', label=statistic,\n",
    "        marker=markers[i_s], markersize=4, linewidth=1)\n",
    "plt.xlabel(r'$\\mathrm{P}_{\\mathrm{FA}}$')\n",
    "plt.ylabel(r'$\\mathrm{P}_{\\mathrm{D}}$')\n",
    "plt.legend()\n",
    "plt.xlim([0.,1])\n",
    "plt.ylim([0,1])\n",
    "matplotlib2tikz.save('./Results/'+dataset_choice+'/Robust_statistics_%dx%d.tex'%(m_r, m_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing statistics results ROC with plotly\n",
    "data = []\n",
    "symbols = ['circle', 'square', 'cross', 'star']\n",
    "for i_s, statistic in enumerate(statistic_names):\n",
    "    trace = go.Scatter(x=pfa_array[:,i_s], y=pd_array[:,i_s], name=statistic, mode = 'lines+markers')\n",
    "    data.append(trace)\n",
    "\n",
    "layout = go.Layout(\n",
    "    width=900,\n",
    "    height=400,\n",
    "    xaxis=dict(\n",
    "        title=r'Probability of false alarm',\n",
    "        type='log',\n",
    "        autorange=True\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        autorange=True, \n",
    "        title=r'Probability of detection',\n",
    "    ),\n",
    "    template='seaborn',\n",
    "    hovermode= 'x',\n",
    "    autosize=False,\n",
    "    font=dict(size=18)\n",
    "    )\n",
    "config = {\n",
    "    'editable': False,\n",
    "    'scrollZoom': True,\n",
    "    'displayModeBar': True,\n",
    "    'showLink': False\n",
    "}\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "iplot(fig, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
